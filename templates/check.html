<!DOCTYPE html>
<html>
<head>
    <title>Job Description Skill Extractor</title>
</head>
<body>
    <h1>Job Description Skill Extractor</h1>

    <form method="POST" action="{{ url_for('get_skills') }}">
        <h3>Job Description:</h3>
        <textarea name="job_desc" rows="20" cols="50"></textarea><br>
        <h3>Resume:</h3>
        <textarea name="resume" rows="20" cols="50"></textarea><br>
        <input type="submit" value="Scan">
    </form>

    <h2>Job Description Skills and Matching:</h2>
    {% if matching_skills or missing_skills %}
        <table>
            <thead>
                <tr>
                    <th>Skill</th>
                    <th>Match</th>
                </tr>
            </thead>
            <tbody>
                {% for skill in matching_skills %}
                    <tr>
                        <td>{{ skill }}</td>
                        <td>&#10003;</td>  <!-- This is a check mark -->
                    </tr>
                {% endfor %}
                {% for skill in missing_skills %}
                    <tr>
                        <td>{{ skill }}</td>
                        <td>&#10007;</td>  <!-- This is a cross mark -->
                    </tr>
                {% endfor %}
            </tbody>
        </table>
    {% else %}
        <p>No skills extracted.</p>
    {% endif %}
    <h2>Job Skills:</h2>
    {% if job_skills %}
        <ul>
            {% for skill in job_skills %}
                <li>{{ skill }}</li>
            {% endfor %}
        </ul>
    {% else %}
        <p>No skills extracted.</p>
    {% endif %}

    <h2>Resume Skills:</h2>
    {% if resume_skills %}
        <ul>
            {% for skill in resume_skills %}
                <li>{{ skill }}</li>
            {% endfor %}
        </ul>
    {% else %}
        <p>No skills extracted.</p>
    {% endif %}
</body>
</html>



from flask import Flask, render_template, request
from src.pipeline.predict_pipeline import PredictPipeline

app = Flask(__name__)

pipeline = PredictPipeline()

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/get_skills', methods=['POST'])
def get_skills():
    job_desc = request.form.get('job_desc')
    resume = request.form.get('resume')

    job_desc_skills = pipeline.evaluate_model(job_desc)
    job_desc_skills_set = set([skill[0] for skill in job_desc_skills])
    
    resume_skills = pipeline.evaluate_model(resume)
    resume_skills_set = set([skill[0] for skill in resume_skills])

    matching_skills = job_desc_skills_set.intersection(resume_skills_set)
    missing_skills = job_desc_skills_set.difference(resume_skills_set)

    return render_template('index.html', matching_skills=matching_skills, missing_skills=missing_skills, job_skills = job_desc_skills_set , resume_skills=resume_skills_set)

if __name__ == '__main__':
    app.run(debug=True)



    <!DOCTYPE html>
    <html>
    <head>
        <title>Job Description Skill Extractor</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                margin: 0;
                padding: 0;
                background-color: #f5f5f5;
            }
            .form-group {
                display: flex;
                justify-content: space-between;
                margin-bottom: 1em;
            }
            h1, h2, h3 {
                color: #333;
            }
            textarea {
                width: 550px;
                min-height: 400px;
                padding: 50px;
                padding-left: 30px;
                border-radius: 50px;
                border: 1px solid #ccc;
                font-size: 1em;
                resize: vertical;
            }
            input[type="submit"] {
                padding: 0.5em 1em;
                border-radius: 4px;
                border: none;
                background-color: #007BFF;
                color: white;
                cursor: pointer;
                display: block;
                margin: 1em auto;
            }
            table {
                width: 100%;
                margin-bottom: 1em;
                border-collapse: collapse;
            }
            th, td {
                padding: 0.5em;
                border: 1px solid #ddd;
            }
            th {
                background-color: #007BFF;
                color: white;
            }
            button {
                padding: 0.5em 1em;
                border-radius: 4px;
                border: none;
                background-color: #007BFF;
                color: white;
                cursor: pointer;
                margin-right: 1em;
            }
        </style>
    </head>
    <body>
    
        <h1>Job Description Skill Extractor</h1>
    
        <form method="POST" action="{{ url_for('get_skills') }}">
            <div class="form-group">
                <div>
                    <h3>Job Description:</h3>
                    <textarea name="job_desc" rows="20"></textarea>
                </div>
                <div>
                    <h3>Resume:</h3>
                    <textarea name="resume" rows="20"></textarea>
                </div>
            </div>
            <input type="submit" value="Scan">
        </form>
    
    
        <h2>Job Description Skills and Matching:</h2>
        {% if matching_skills or missing_skills %}
            <table>
                <thead>
                    <tr>
                        <th>Skill</th>
                        <th>Match</th>
                    </tr>
                </thead>
                <tbody>
                    {% for skill in matching_skills %}
                        <tr>
                            <td>{{ skill }}</td>
                            <td>&#10003;</td>  <!-- This is a check mark -->
                        </tr>
                    {% endfor %}
                    {% for skill in missing_skills %}
                        <tr>
                            <td>{{ skill }}</td>
                            <td>&#10007;</td>  <!-- This is a cross mark -->
                        </tr>
                    {% endfor %}
                </tbody>
            </table>
        {% else %}
            <p>No skills extracted.</p>
        {% endif %}
    
        <button id="toggleJob">Toggle Job Skills</button>
        <button id="toggleResume">Toggle Resume Skills</button>
    
        <div id="job_skills" class="hidden">
            <h3>Job Skills:</h3>
            {% if job_skills %}
                <ul>
                    {% for skill in job_skills %}
                    <li>{{ skill }}</li>
                {% endfor %}
                </ul>
            {% else %}
                <p>No skills extracted.</p>
            {% endif %}
        </div>
    
        <div id="resume_skills" class="hidden">
            <h3>Resume Skills:</h3>
            {% if resume_skills %}
                <ul>
                    {% for skill in resume_skills %}
                    <li>{{ skill }}</li>
                {% endfor %}
                </ul>
            {% else %}
                <p>No skills extracted.</p>
            {% endif %}
        </div>
    
        <script>
            document.getElementById('toggleJob').onclick = function() {
                var job_skills = document.getElementById('job_skills');
                if (job_skills.style.display !== 'none') {
                    job_skills.style.display = 'none';
                } else {
                    job_skills.style.display = 'block';
                }
            };
            document.getElementById('toggleResume').onclick = function() {
                var resume_skills = document.getElementById('resume_skills');
                if (resume_skills.style.display !== 'none') {
                    resume_skills.style.display = 'none';
                } else {
                    resume_skills.style.display = 'block';
                }
            };
        </script>
    </body>
    </html>

    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f5f5f5;
        }
        .form-group {
            display: flex;
            justify-content: space-between;
            margin-bottom: 1em;
        }
        h1, h2, h3 {
            color: #333;
        }
        textarea {
            width: 550px;
            min-height: 400px;
            padding: 50px;
            padding-left: 30px;
            border-radius: 50px;
            border: 1px solid #ccc;
            font-size: 1em;
            resize: vertical;
        }
        input[type="submit"] {
            padding: 0.5em 1em;
            border-radius: 4px;
            border: none;
            background-color: #007BFF;
            color: white;
            cursor: pointer;
            display: block;
            margin: 1em auto;
        }
        table {
            width: 100%;
            margin-bottom: 1em;
            border-collapse: collapse;
        }
        th, td {
            padding: 0.5em;
            border: 1px solid #ddd;
        }
        th {
            background-color: #007BFF;
            color: white;
        }
        button {
            padding: 0.5em 1em;
            border-radius: 4px;
            border: none;
            background-color: #007BFF;
            color: white;
            cursor: pointer;
            margin-right: 1em;
        }
    </style>
</head>








# data ingestion


from pymongo import MongoClient
import pandas as pd
import time



def fetch_data():
    # Create a client
    client = MongoClient('mongodb://localhost:27017/')

# Connect to your database
    db = client['job_db']
    # Get your collection
    collection = db['Annotate_data_1']

    # Fetch all documents from your collection
    data = list(collection.find({}))

    # Convert data to pandas DataFrame
    df = pd.DataFrame(data)
    data = []
    for i in range(len(df)):
        text = df.iloc[i]['text']
        entities = df.iloc[i]['label']
        data.append((text, {"entities": entities}))
    clean_data = remove_overlapping_entities(data)
    return clean_data

def fetch_test_data():
    client = MongoClient('mongodb://localhost:27017/')
    db = client['job_db']
    collection = db['test_data']  # use your test data collection
    data = list(collection.find({}))
    df = pd.DataFrame(data)
    data = []
    for i in range(len(df)):
        text = df.iloc[i]['text']
        entities = df.iloc[i]['label']
        data.append((text, {"entities": entities}))
    clean_data = remove_overlapping_entities(data)
   
    return clean_data

def remove_overlapping_entities(data):
    result = []
    for text, annot in data:
        entities = sorted(annot["entities"], key=lambda x: x[0]) # Sort entities by start character
        non_overlapping_entities = []
        prev_entity = entities[0]
        for curr_entity in entities[1:]:
            # If the start of current entity is inside the previous entity span, it is an overlap
            if curr_entity[0] < prev_entity[1]:
                # Take the longer entity
                if (curr_entity[1]-curr_entity[0]) > (prev_entity[1]-prev_entity[0]):
                    prev_entity = curr_entity
            else:
                non_overlapping_entities.append(prev_entity)
                prev_entity = curr_entity
        non_overlapping_entities.append(prev_entity) # add the last entity
        result.append((text, {"entities": non_overlapping_entities}))
    return result
if __name__=="__main__":
    fetch_data()
    fetch_test_data()





#model test 



import spacy
from src.components.data_ingestion import fetch_test_data
import re


def evaluate_model(nlp, test_data):

    def preprocess_text(text):
        text = re.sub('\s+', ' ', text)
        text = text.strip()
        return text

    # Initialize counters for correctly recognized entities and total entities
    correct_entities = 0
    total_entities = 0

    for text, annotations in test_data:
        text = preprocess_text(text)
        print(text)

        # Get the original words that are entities
        original_entities = [text[start:end] for start, end, label in annotations['entities']]

        # Update total_entities
        total_entities += len(original_entities)

        # Predict entities using the model
        doc = nlp(text)

        # Get the words that the model predicts as entities
        predicted_entities = [ent.text for ent in doc.ents]

        # Check how many entities are correctly predicted
        correct_entities += len([entity for entity in original_entities if entity in predicted_entities])
        for ent in doc.ents:
            print(ent.text, ent.label_)

    # Calculate the accuracy
    accuracy = correct_entities / total_entities * 100
    print(accuracy)
    return accuracy

if __name__ == "__main__":
    nlp = spacy.load(r"C:\Users\HP\Desktop\job_scan\artifact\spacy_model")
    test_data = fetch_test_data()
    acc = evaluate_model(nlp , test_data)






#   model_train


import spacy
import pickle
from spacy.training import Example
import random
from spacy.training import offsets_to_biluo_tags

from src.components.data_ingestion import fetch_data, fetch_test_data


def train_model(data):
   
    # Load the existing model
    nlp = spacy.load("en_core_web_sm")

    # Get the NER pipeline component
    ner = nlp.get_pipe("ner")

    # Add labels
    for _, annotations in data:
        for ent in annotations.get("entities"):
            ner.add_label(ent[2])

    # Disable other components for efficient training
    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != "ner"]
    with nlp.disable_pipes(*other_pipes): 
        # Only train NER
        optimizer = nlp.resume_training()

        # Create a list of examples
        examples = [Example.from_dict(nlp.make_doc(text), annotations) for text, annotations in data]

        # Train for 60 iterations
        for itn in range(60):
            random.shuffle(examples)
            losses = {}
            for batch in spacy.util.minibatch(examples, size=2):
                nlp.update(batch, sgd=optimizer, losses=losses)
            print(losses)

    # Instead of saving the model to disk here, we return it
    return nlp

if __name__=="__main__":
    train_data = fetch_data()
    train_model(train_data)









# from spacy.training import offsets_to_biluo_tags

# # Load the existing model
# nlp = spacy.load("en_core_web_sm")

# # Get the NER pipeline component
# ner = nlp.get_pipe("ner")

# data = fetch_data()

# # Add labels
# for _, annotations in data:
#     for ent in annotations.get("entities"):
#         ner.add_label(ent[2])

# # Disable other components for efficient training
# other_pipes = [pipe for pipe in nlp.pipe_names if pipe != "ner"]
# with nlp.disable_pipes(*other_pipes): 
#     # Only train NER
#     optimizer = nlp.resume_training()

#     # Create a list of examples
#     examples = [Example.from_dict(nlp.make_doc(text), annotations) for text, annotations in data]

#     # Train for 150 iterations
#     for itn in range(60):
#         random.shuffle(examples)
#         losses = {}
#         for batch in spacy.util.minibatch(examples, size=2):
#             nlp.update(batch, sgd=optimizer, losses=losses)
#         print(losses)



# nlp.to_disk(r"C:\Users\HP\Desktop\job_scan\artifact\spacy_model")






create_train_data_pipeline 

import spacy
import pandas as pd
from sqlalchemy import create_engine, Table, Column, String, MetaData, Text
from pymongo import MongoClient
from sqlalchemy import create_engine
import urllib
import pyodbc
import json
import spacy
from create_training_data.get_initial_data import fetch_data_from_sql, process_data_through_spacy,insert_into_mongodb,save_to_local_directory
from src.components.model_train import train_model
from src.components.model_test import evaluate_model

# Establish a connection to the SQL Server
params = urllib.parse.quote_plus(r'DRIVER={SQL Server};SERVER=HP-ELITEBOOK\SQLEXPRESS;DATABASE=job_scan;Trusted_Connection=yes;')
engine = create_engine("mssql+pyodbc:///?odbc_connect=%s" % params)

# Load the spaCy model
nlp = spacy.load(r"C:\Users\HP\Desktop\job_scan\artifact\spacy_model")

# MongoDB Connection
client = MongoClient('mongodb://localhost:27017/')
db = client['job_db']  # Use your desired database
collection = db['pre_annotate_data']  # Use your desired collection


df = fetch_data_from_sql(engine)
annotations = process_data_through_spacy(df, nlp)
save_to_local_directory(annotations, r'C:\Users\HP\Desktop\job_scan\pre_anootate_data')
insert_into_mongodb(annotations, collection)








##predict_pipeline

import spacy
from src.components.data_ingestion import fetch_data, fetch_test_data
from src.components.model_train import train_model
from src.components.model_test import evaluate_model
import os


# Directory where models are saved
model_directory = r"C:\Users\HP\Desktop\job_scan\artifact"

def get_latest_model_path():
    """Fetches the latest model based on the versioning in the name"""
    models = [f for f in os.listdir(model_directory) if os.path.isdir(os.path.join(model_directory, f)) and f.startswith('model')]
    models.sort()
    if models:
        return os.path.join(model_directory, models[-1])
    else:
        return None

def main():
    # Fetch training and test data
    training_data = fetch_data()
    test_data = fetch_test_data()

    # Train a new model
    new_model = train_model(training_data)

    # Calculate accuracy of the new model
    new_model_accuracy = evaluate_model(new_model, test_data)

    # Get the path of the latest model in the artifact directory
    latest_model_path = get_latest_model_path()
    if latest_model_path:
        # If there is a previous model, load it and calculate its accuracy
        old_model = spacy.load(latest_model_path)
        old_model_accuracy = evaluate_model(old_model, test_data)
    else:
        # If there is no previous model, set its accuracy as 0
        old_model_accuracy = 0

    # If the new model performs better, save it
    if new_model_accuracy > old_model_accuracy:
        new_version = int(latest_model_path.split('model')[-1]) + 1 if latest_model_path else 1
        new_model_path = os.path.join(model_directory, f'model{new_version}')
        new_model.to_disk(new_model_path)
        print(f"New model saved at {new_model_path} with accuracy {new_model_accuracy:.2f}%")
    else:
        print(f"Old model is better. No new model saved. Old model accuracy: {old_model_accuracy:.2f}%")

if __name__ == "__main__":
    main()








  #  get_initial_data


  import spacy
import pandas as pd
from sqlalchemy import create_engine, Table, Column, String, MetaData, Text
from pymongo import MongoClient
from sqlalchemy import create_engine
import urllib
import pyodbc
import json
import spacy
from src.components.data_ingestion import fetch_data, fetch_test_data
from src.components.model_train import train_model
from src.components.model_test import evaluate_model
from datetime import datetime
import os

# # Establish a connection to the SQL Server
# params = urllib.parse.quote_plus(r'DRIVER={SQL Server};SERVER=HP-ELITEBOOK\SQLEXPRESS;DATABASE=job_scan;Trusted_Connection=yes;')
# engine = create_engine("mssql+pyodbc:///?odbc_connect=%s" % params)

# # Load the spaCy model
# nlp = spacy.load(r"C:\Users\HP\Desktop\job_scan\artifact\spacy_model")


# # Establish a connection to the SQL Server
# params = urllib.parse.quote_plus(r'DRIVER={SQL Server};SERVER=HP-ELITEBOOK\SQLEXPRESS;DATABASE=job_scan;Trusted_Connection=yes;')
# engine = create_engine("mssql+pyodbc:///?odbc_connect=%s" % params)

# # Load the spaCy model
# nlp = spacy.load(r"C:\Users\HP\Desktop\job_scan\artifact\spacy_model")

# # MongoDB Connection
# client = MongoClient('mongodb://localhost:27017/')
# db = client['job_db']  # Use your desired database
# collection = db['pre_annotate_data']  # Use your desired collection


def fetch_data_from_sql(engine):
    """
    Function to fetch data from SQL database
    """
    data = []
    df = pd.read_sql('SELECT * FROM job_data', engine)
    for i in df['job_description']:
        data.append(i)
    a = ''.join(data)
    return a

def process_data_through_spacy(data, nlp):
    """
    Function to process data through the spaCy model
    """
    annotations = []

    doc = nlp(data)
        
        # Extract annotations
    entities = [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]
        
        # Append to annotations list
    annotations.append({"text": data, "entities": entities})
    return annotations

# To make sure Docanno can understand the file we ned to convert the file formet

def converted_data(data):
    converted_data = []

    for index, item in enumerate(data):
        new_item = {}
        new_item["id"] = index + 1
        new_item["text"] = item["text"]

        # Remove the text segment from each entity
        new_item["label"] = [[entity[1], entity[2], entity[3]] for entity in item["entities"]]

        new_item["Comments"] = []  # add this if your output also requires the "Comments" field
        converted_data.append(new_item)

    return converted_data

def save_to_local_directory(annotations, directory):
    data = converted_data(annotations)
    os.makedirs(directory, exist_ok=True)

    # Use current date and time to create a unique filename
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"annotations_{timestamp}.jsonl"
    filepath = os.path.join(directory, filename)
    with open(filepath, 'w') as f:  # replace 'newfile.jsonl' with your desired filename
        for item in data:
            json.dump(item, f)
            f.write('\n')

    # with open(filepath, 'w') as f:
    #     json.dump(annotations, f)

def insert_into_mongodb(annotations, collection):
    data = converted_data(annotations)
    """
    Function to insert data into MongoDB
    """
    # Insert annotations into MongoDB
    for annotation in data:
        collection.insert_one(annotation)

# df = fetch_data_from_sql(engine)
# annotations = process_data_through_spacy(df, nlp)
# save_to_local_directory(annotations, r'C:\Users\HP\Desktop\job_scan\pre_anootate_data')
# insert_into_mongodb(annotations, collection)




   
